{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([500, 500, 500, 500, 500, 500, 500, 500, 500, 500], dtype=int64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_data = loadmat(\"Data/ex3data1.mat\")\n",
    "data = mat_data['X']\n",
    "label = mat_data['y']\n",
    "print(data.shape, label.shape)\n",
    "label = np.where(label==10,0,label)\n",
    "np.unique(label, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), array([375, 375, 375, 375, 375, 375, 375, 375, 375, 375], dtype=int64))\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), array([125, 125, 125, 125, 125, 125, 125, 125, 125, 125], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "new_data = np.hstack((label, data))\n",
    "np.random.shuffle(new_data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(new_data, shuffle = True, stratify = new_data[:,0])\n",
    "\n",
    "train_y, train_x = train_data[:,0], train_data[:,1:]\n",
    "print(np.unique(train_y, return_counts = True))\n",
    "test_y, test_x = test_data[:,0], test_data[:,1:]\n",
    "print(np.unique(test_y, return_counts = True))\n",
    "m, n = train_x.shape[0], test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(X, example_width=None, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Displays 2D data stored in X in a nice grid.\n",
    "    \"\"\"\n",
    "    # Compute rows, cols\n",
    "    if X.ndim == 2:\n",
    "        m, n = X.shape\n",
    "    elif X.ndim == 1:\n",
    "        n = X.size\n",
    "        m = 1\n",
    "        X = X[None]  # Promote to a 2 dimensional array\n",
    "    else:\n",
    "        raise IndexError('Input X should be 1 or 2 dimensional.')\n",
    "\n",
    "    example_width = example_width or int(np.round(np.sqrt(n)))\n",
    "    example_height = n / example_width\n",
    "\n",
    "    # Compute number of items to display\n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m / display_rows))\n",
    "\n",
    "    fig, ax_array = plt.subplots(display_rows, display_cols, figsize=figsize)\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "\n",
    "    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n",
    "\n",
    "    for i, ax in enumerate(ax_array):\n",
    "        # Display Image\n",
    "        h = ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n",
    "                      cmap='Greys', extent=[0, 1, 0, 1])\n",
    "\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Actual Value is :  0.0  Predicted value is :  0.0\n",
      "The Actual Value is :  3.0  Predicted value is :  3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEuklEQVR4nO2dyyttYRjGv+2yc2ckJSSJXDMyYqCUMkFKblP/g1KSy8iQmDEmykSiZGTARBlQhkbKJUK5n8HpjN7n2+2VtexzzvP8ho9nH5vfWfXutb7vE/v6+nKCg7RUvwHxc0g2EZJNhGQTIdlESDYRGYm++Pr6qs9l/xjxeDzm+5qubCIkmwjJJkKyiZBsIiSbCMkmQrKJkGwiJJsIySZCsomQbCIkmwjJJiLh8+yfJBbDj2HT0pL///j5+ZlUj3X5tK5sIiSbCMkmQrKJkGwiUjKNp6enm+zl5QV2d3d3TZaXlwe7bW1tJkPTfEbG93/sj48Pk/3tU76ubCIkmwjJJkKyiYh0QPPd6ry6ujLZ3Nwc7K6vr5ssOzsbdvv6+kxWWVlpss7OTvh6RGZmJsxLS0uT7qJhLhXoyiZCsomQbCIkmwjJJiKW6BZfkM34aPGBbwqdnJw02dLSEuzm5OSY7O3tDXZRjj4R+KZmRG5uLsxHRkZMNjAwALt1dXUm8/3ek12A4UOb8YVzTrKpkGwiJJuI0AY09Iwa3RZ1zrnh4WGTnZycJPutXElJCczLyspM1traajLf0HVxcWGyvb092L25uTFZcXEx7NbX15tsdnYWdhsbG032/v4OuwgNaMI5J9lUSDYRkk2EZBMR2uIFdFvy9PQUdo+Pj03W3NwMu6Ojoybr7u6G3YKCApOh263ok4NzeIXr2dkZ7K6trZlsZWUFdvf39022sLAAu/Pz8yZDP4NzwVez6somQrKJkGwiJJuI0AY09Dz76ekJdp+fn01WXV0Nu2NjYyYL8iwYdX23H9G2oJaWFtitra01WVNTE+xOTEyYbGNjA3bb29tNNjQ0BLtBV63qyiZCsomQbCIkm4iUbP9B+IaNZBcROvf9/dHo9b7FjfF43GT9/f2wu729bbKtrS3YXV1dNZlvQAuKrmwiJJsIySZCsomQbCIincZ9EzaaeoPc+vOdcxrFaUVBvpfvFKaOjg6TbW5uwq5v+g8DXdlESDYRkk2EZBMR2oCGniVXVVXBLsoPDw9hd3p62mTj4+OwixbmfXdo8+2XRv/uw8MD7B4cHJjMN8z5thCFga5sIiSbCMkmQrKJkGwiQpvG0e3Ompoa2O3q6jKZb+sM2ibjm2R7enpMlpWVZTLfhI5ujaIN+s45d35+brKdnR3YRZ80BgcHYXdqaspk3z1B6Q+6somQbCIkmwjJJiK005IQvlWgt7e3JltcXITd5eVlkz0+PsIuutWIVoH63hd6lnx/fw+7d3d3JissLITd3t5ek6EtQc45V15ebjKdliQCI9lESDYRkk2EZBMR6TTuA51W5FtVeXR0ZLKZmRnYRVM+OhDg+voavr6iosJkaNO9c/hPPaGp2zl8EpTvgHsdLi9CQbKJkGwiJJuIlAxo8I14ttmgW5u+Q+vRkIdWfF5eXsLXNzQ0mKyoqAh28/PzTeYbrpI9xSkMNKAJ55xkUyHZREg2EZJNxF8zjQfBdzh8FET1NzOjQtO4cM5JNhWSTYRkExHpaUlREfRQdfEbXdlESDYRkk2EZBMh2URINhGSTYRkEyHZREg2EQmfZ4v/C13ZREg2EZJNhGQTIdlESDYRvwBFjV0tceLLrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEZUlEQVR4nO2dvSu9cRjG7+PtEBGDkjLKZDGQgYFJEYMUKZPBbDKymEQpUWZhMBgtpIwGo6QsTPKaHK+/P+C+vqfz/HjOeY7r+oyX+6nn9Olbt+/bk/r+/jbBQUmhX0DkD8kmQrKJkGwiJJsIySaiLNsfM5mM/i8rMtLpdCr0N41sIiSbCMkmQrKJyNqgFRuplO9NUBaF0NpBMa4paGQTIdlESDYRkk2EZBNRlN14aWkpzD8+Plz2+vrqspeXF/g86rBra2thbTqdzun5JKGRTYRkEyHZREg2EYlv0NB059nZGazd2tpy2cnJSc7Pv729uWxiYgLWrqysuAw1bWbJadw0somQbCIkmwjJJkKyiUhl6xTzubs0tMng4eHBZcPDw7C2paXFZePj4y5ra2uDzx8cHLhscXER1u7u7rqso6MD1n5+fsI8DrS7VJiZZFMh2URINhGJmS4NNWj39/cuq6+vh7Wbm5suq6iocFlZGf7Zl5eXLispweOhvLwc5klGI5sIySZCsomQbCIkm4jEdOOhadumpiaXzczMwFq0+aCystJl19fX8Pnl5WWXdXd3w9rW1laXfX19wdqkoJFNhGQTIdlESDYRiW/Q0HRnf38/rEXHeqKsUR8eHrpsdXUV1qIjSKEpX+0uFXlHsomQbCIkmwjJJiIxu0ujENpQcHt767LZ2VmXZTIZ+DyaWj06OoK1g4ODLltYWIC1NTU1LourQ9fuUmFmkk2FZBMh2UQUZYMWAq0nPz8/uyx0aB41fqenp7B2dHTUZWtra7B2aGjIZXEdCVKDJsxMsqmQbCIkm4jENGhxrQWHZttyJfReS0tLLjs+Poa129vbLgsdQfrp71WDJsxMsqmQbCIkmwjJJqIgu0tRx4mO7pjhNeYon1/66ZGc0KH73t5el62vr8Pax8dHlzU0NPzovf4HjWwiJJsIySZCsomItUGLckXlyMgIrEVXVE5NTcFa1DTF9S3Om5sbl6GvD/3GO/wWGtlESDYRkk2EZBMh2UQkZrr0/Pwc1nZ1dbmsqqoK1r6/v7ssyjcz0YYCdKTIzGx+ft5lk5OTsBbdtVqIA/oa2URINhGSTYRkExFrgxZqQurq6lwWam7Q5fKdnZ2wFq09o/Xs0Br3xcWFy+bm5mAt+g2hazbRdKkaNBErkk2EZBMh2URINhEFmS5F05JjY2OwdmBgwGXNzc2wdnp62mXo8037+/vw+Z2dHZe1t7fD2o2NDZc1NjbC2nx+izMbGtlESDYRkk2EZBNRkMP4aPowtDNzb2/PZaiRMjO7urpy2d3dnct6enrg8319fS4L7Xqtrq52WRIaMR3GF2Ym2VRINhGSTYRkE1GUV2OFLod/enpyGZqaRZe9m0XbiZrU726qGxdmJtlUSDYRkk1EYhq0KISauVwPvUe5banYUIMmzEyyqZBsIiSbCMkmoiC7S3/KX+6m40QjmwjJJkKyiZBsIrJOl4q/hUY2EZJNhGQTIdlESDYRkk3EP9NtUD49jgkmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_data(data, label, Actval, size, print_val, figsize):\n",
    "    for i in range(print_val):\n",
    "        ind = np.random.randint(size)\n",
    "        print(\"The Actual Value is : \", Actval[ind], \" Predicted value is : \",label[ind])\n",
    "        displayData(data[ind], figsize = figsize)\n",
    "    \n",
    "print_data(train_x, train_y, train_y, m, 2, (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data,categ):\n",
    "    new_label = []\n",
    "    for i in range(categ):\n",
    "        new_label.append(np.where(data!=i, 0, 1))\n",
    "    new_label = np.array(new_label).T\n",
    "    np.unique(new_label[0],return_counts=True)\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 10)\n",
      "(1250, 10)\n"
     ]
    }
   ],
   "source": [
    "train_y = one_hot_encode(train_y, 10)\n",
    "print(train_y.shape)\n",
    "test_y = one_hot_encode(test_y, 10)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 10:42:40.290461  2268 deprecation.py:506] From C:\\Users\\naoggu\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2512 samples, validate on 1238 samples\n",
      "Epoch 1/100\n",
      "2512/2512 [==============================] - 0s 93us/sample - loss: 1.8074 - acc: 0.4996 - val_loss: 1.2178 - val_acc: 0.7124\n",
      "Epoch 2/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.8733 - acc: 0.7874 - val_loss: 0.6736 - val_acc: 0.8288\n",
      "Epoch 3/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.5594 - acc: 0.8455 - val_loss: 0.5042 - val_acc: 0.8659\n",
      "Epoch 4/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.4156 - acc: 0.8921 - val_loss: 0.4272 - val_acc: 0.8821\n",
      "Epoch 5/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.3365 - acc: 0.9164 - val_loss: 0.3749 - val_acc: 0.8998\n",
      "Epoch 6/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.2901 - acc: 0.9271 - val_loss: 0.3486 - val_acc: 0.9055\n",
      "Epoch 7/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.2468 - acc: 0.9399 - val_loss: 0.3244 - val_acc: 0.9144\n",
      "Epoch 8/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.2218 - acc: 0.9427 - val_loss: 0.3104 - val_acc: 0.9176\n",
      "Epoch 9/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.1981 - acc: 0.9506 - val_loss: 0.3029 - val_acc: 0.9233\n",
      "Epoch 10/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1740 - acc: 0.9598 - val_loss: 0.2904 - val_acc: 0.9241\n",
      "Epoch 11/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1566 - acc: 0.9610 - val_loss: 0.2996 - val_acc: 0.9233\n",
      "Epoch 12/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1419 - acc: 0.9674 - val_loss: 0.2773 - val_acc: 0.9225\n",
      "Epoch 13/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1287 - acc: 0.9674 - val_loss: 0.2790 - val_acc: 0.9241\n",
      "Epoch 14/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1185 - acc: 0.9741 - val_loss: 0.2668 - val_acc: 0.9281\n",
      "Epoch 15/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.1088 - acc: 0.9769 - val_loss: 0.2655 - val_acc: 0.9249\n",
      "Epoch 16/100\n",
      "2512/2512 [==============================] - 0s 28us/sample - loss: 0.0947 - acc: 0.9821 - val_loss: 0.2656 - val_acc: 0.9273\n",
      "Epoch 17/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0856 - acc: 0.9841 - val_loss: 0.2633 - val_acc: 0.9257\n",
      "Epoch 18/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0774 - acc: 0.9857 - val_loss: 0.2723 - val_acc: 0.9257\n",
      "Epoch 19/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0685 - acc: 0.9877 - val_loss: 0.2640 - val_acc: 0.9297\n",
      "Epoch 20/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0634 - acc: 0.9893 - val_loss: 0.2616 - val_acc: 0.9233\n",
      "Epoch 21/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0590 - acc: 0.9908 - val_loss: 0.2653 - val_acc: 0.9321\n",
      "Epoch 22/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0543 - acc: 0.9916 - val_loss: 0.2644 - val_acc: 0.9289\n",
      "Epoch 23/100\n",
      "2512/2512 [==============================] - 0s 30us/sample - loss: 0.0468 - acc: 0.9948 - val_loss: 0.2584 - val_acc: 0.9265\n",
      "Epoch 24/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0416 - acc: 0.9952 - val_loss: 0.2613 - val_acc: 0.9354\n",
      "Epoch 25/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0385 - acc: 0.9956 - val_loss: 0.2674 - val_acc: 0.9305\n",
      "Epoch 26/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0442 - acc: 0.9928 - val_loss: 0.2598 - val_acc: 0.9338\n",
      "Epoch 27/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0334 - acc: 0.9972 - val_loss: 0.2633 - val_acc: 0.9330\n",
      "Epoch 28/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0299 - acc: 0.9972 - val_loss: 0.2723 - val_acc: 0.9321\n",
      "Epoch 29/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0269 - acc: 0.9984 - val_loss: 0.2654 - val_acc: 0.9338\n",
      "Epoch 30/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0244 - acc: 0.9984 - val_loss: 0.2670 - val_acc: 0.9362\n",
      "Epoch 31/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0224 - acc: 0.9984 - val_loss: 0.2665 - val_acc: 0.9330\n",
      "Epoch 32/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0207 - acc: 0.9992 - val_loss: 0.2670 - val_acc: 0.9297\n",
      "Epoch 33/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0195 - acc: 0.9988 - val_loss: 0.2688 - val_acc: 0.9354\n",
      "Epoch 34/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.2725 - val_acc: 0.9321\n",
      "Epoch 35/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.2759 - val_acc: 0.9338\n",
      "Epoch 36/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0146 - acc: 0.9996 - val_loss: 0.2735 - val_acc: 0.9289\n",
      "Epoch 37/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.2737 - val_acc: 0.9313\n",
      "Epoch 38/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.2789 - val_acc: 0.9321\n",
      "Epoch 39/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.2809 - val_acc: 0.9305\n",
      "Epoch 40/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2799 - val_acc: 0.9297\n",
      "Epoch 41/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2783 - val_acc: 0.9305\n",
      "Epoch 42/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2776 - val_acc: 0.9289\n",
      "Epoch 43/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2830 - val_acc: 0.9330\n",
      "Epoch 44/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.2834 - val_acc: 0.9305\n",
      "Epoch 45/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.2845 - val_acc: 0.9330\n",
      "Epoch 46/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.2856 - val_acc: 0.9289\n",
      "Epoch 47/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.2837 - val_acc: 0.9305\n",
      "Epoch 48/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2872 - val_acc: 0.9346\n",
      "Epoch 49/100\n",
      "2512/2512 [==============================] - 0s 27us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.2877 - val_acc: 0.9289\n",
      "Epoch 50/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9313\n",
      "Epoch 51/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2913 - val_acc: 0.9313\n",
      "Epoch 52/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2926 - val_acc: 0.9321\n",
      "Epoch 53/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2969 - val_acc: 0.9321\n",
      "Epoch 54/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 0.9338\n",
      "Epoch 55/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2963 - val_acc: 0.9313\n",
      "Epoch 56/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2987 - val_acc: 0.9346\n",
      "Epoch 57/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2950 - val_acc: 0.9338\n",
      "Epoch 58/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2976 - val_acc: 0.9321\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2992 - val_acc: 0.9330\n",
      "Epoch 60/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 0.9313\n",
      "Epoch 61/100\n",
      "2512/2512 [==============================] - 0s 23us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.9321\n",
      "Epoch 62/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9305\n",
      "Epoch 63/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.9330\n",
      "Epoch 64/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.9305\n",
      "Epoch 65/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3065 - val_acc: 0.9313\n",
      "Epoch 66/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.9297\n",
      "Epoch 67/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.9321\n",
      "Epoch 68/100\n",
      "2512/2512 [==============================] - 0s 30us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.9305\n",
      "Epoch 69/100\n",
      "2512/2512 [==============================] - 0s 33us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.9305\n",
      "Epoch 70/100\n",
      "2512/2512 [==============================] - 0s 30us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.9321\n",
      "Epoch 71/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3108 - val_acc: 0.9321\n",
      "Epoch 72/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3124 - val_acc: 0.9313\n",
      "Epoch 73/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.9305\n",
      "Epoch 74/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.9338\n",
      "Epoch 75/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3173 - val_acc: 0.9313\n",
      "Epoch 76/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3178 - val_acc: 0.9330\n",
      "Epoch 77/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3178 - val_acc: 0.9321\n",
      "Epoch 78/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3185 - val_acc: 0.9321\n",
      "Epoch 79/100\n",
      "2512/2512 [==============================] - 0s 23us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.9305\n",
      "Epoch 80/100\n",
      "2512/2512 [==============================] - 0s 23us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.3213 - val_acc: 0.9313\n",
      "Epoch 81/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9313\n",
      "Epoch 82/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3227 - val_acc: 0.9321\n",
      "Epoch 83/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3227 - val_acc: 0.9321\n",
      "Epoch 84/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.9321\n",
      "Epoch 85/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3250 - val_acc: 0.9330\n",
      "Epoch 86/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3256 - val_acc: 0.9330\n",
      "Epoch 87/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3274 - val_acc: 0.9313\n",
      "Epoch 88/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3287 - val_acc: 0.9346\n",
      "Epoch 89/100\n",
      "2512/2512 [==============================] - 0s 27us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3278 - val_acc: 0.9321\n",
      "Epoch 90/100\n",
      "2512/2512 [==============================] - 0s 32us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3290 - val_acc: 0.9330\n",
      "Epoch 91/100\n",
      "2512/2512 [==============================] - 0s 30us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3322 - val_acc: 0.9313\n",
      "Epoch 92/100\n",
      "2512/2512 [==============================] - 0s 27us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3309 - val_acc: 0.9321\n",
      "Epoch 93/100\n",
      "2512/2512 [==============================] - 0s 26us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3334 - val_acc: 0.9321\n",
      "Epoch 94/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3318 - val_acc: 0.9313\n",
      "Epoch 95/100\n",
      "2512/2512 [==============================] - 0s 29us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3336 - val_acc: 0.9330\n",
      "Epoch 96/100\n",
      "2512/2512 [==============================] - 0s 33us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3331 - val_acc: 0.9321\n",
      "Epoch 97/100\n",
      "2512/2512 [==============================] - 0s 31us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3346 - val_acc: 0.9313\n",
      "Epoch 98/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3357 - val_acc: 0.9330\n",
      "Epoch 99/100\n",
      "2512/2512 [==============================] - 0s 24us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3370 - val_acc: 0.9313\n",
      "Epoch 100/100\n",
      "2512/2512 [==============================] - 0s 25us/sample - loss: 9.8583e-04 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.9305\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(400))\n",
    "model.add(layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(layers.Dense(32, activation = tf.nn.relu))\n",
    "model.add(layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['acc'])\n",
    "history = model.fit( train_x, train_y, validation_split=0.33, epochs=100, batch_size=100, shuffle = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss       acc  val_loss   val_acc\n",
      "10  0.156599  0.960987  0.299572  0.923263\n",
      "11  0.141925  0.967357  0.277349  0.922456\n",
      "12  0.128713  0.967357  0.279010  0.924071\n",
      "13  0.118498  0.974124  0.266777  0.928110\n",
      "14  0.108776  0.976911  0.265534  0.924879\n",
      "15  0.094683  0.982086  0.265616  0.927302\n",
      "16  0.085580  0.984076  0.263276  0.925687\n",
      "17  0.077449  0.985669  0.272276  0.925687\n",
      "18  0.068539  0.987659  0.263956  0.929725\n",
      "19  0.063432  0.989252  0.261589  0.923263\n",
      "The Actual Value is :  6  Predicted value is :  6\n",
      "The Actual Value is :  6  Predicted value is :  6\n",
      "The Actual Value is :  0  Predicted value is :  0\n",
      "The Actual Value is :  2  Predicted value is :  2\n",
      "The Actual Value is :  7  Predicted value is :  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEkUlEQVR4nO2dOy+sURSG17hMhLg0RFwKvUai0PoBCFGLgkaiIBqRKBB/QKdTKAiNRqKQUOiUhESEBo2IazFu5wesd03MGd/MnPO+T/lam48nO1n2t/ee1Pf3twkOyor9AKJwSDYRkk2EZBMh2URINhEV2b6YyWT0f9k/RjqdTkVf08wmQrKJkGwiJJuIrA1avqRSYa/gKIU1+lyet6zMz5Pod/j6+vrrZ/pNNLOJkGwiJJsIySZCson4tW4cdbJRF/r4+Oiy2tpaWFtR4R8x38496rpRfnt7C2vn5+ddNjc3B2s7Ojpc9vn5me0RE0EzmwjJJkKyiZBsIhJdLs1kMjCvrq72DwIaMbP8mzG0rIkyM7P9/X2XHRwcwNq1tTWXXV5ewtqdnR2Xob+BWbLLxprZREg2EZJNhGQTIdlE/Fo3jrrIqqqqvMbnSnl5ucve3t5ctrm5CccvLS257OnpCdai/x6ur69hbSlszDDTzKZCsomQbCIkm4hEl0uTakwqKythjt6TT09Pu2x9fR2Oj5ZREUNDQy6bmpqCtTU1NT/+vkmimU2EZBMh2URINhGSTUSi3XguRDs+0RLo4eEhrF1dXXXZ1taWy3LpuoeHh2G+srLismiHLNplW4wlVM1sIiSbCMkmQrKJSGVrFAp5W1LUNJ2cnLisv78f1t7c3LisoaHBZW1tbXD84uKiy3p7e2EtelcfHXcqZDOm25KEmUk2FZJNhGQTIdlEFGW5FC2Boo0HZmYzMzMuQ123GT7gPjY25rKJiQk4vr29/Uff08zs5eXFZel0GtYmcaHA36CZTYRkEyHZREg2EUW5uxQ1J9vb27D26OjIZVEj1NfX57Lx8XGX1dfXw/EbGxsuOz4+hrUo7+zshLULCwsu02F8kSiSTYRkEyHZRCT6Pjt6R313d+eynp4eWHt/f++ypqYmWLu8vOyys7Mzl+3u7sLxp6enLotW0NC766h2dnbWZegsuJnZ+/s7zH+K3mcLM5NsKiSbCMkmQrKJKMpy6cXFhcui99no3Xd0g9Hk5KTLnp+fXRYd5kc/C2UR0V2t0b2shUYzmwjJJkKyiZBsIorSOaBl1KgRQkuQHx8fsBYt/aKbiurq6uD4h4cHmOeLGjRRcCSbCMkmQrKJkGwiSqNN/CV++sn20XIp6uajThpdWh/tWh0ZGXGZPotTJIpkEyHZREg2EUVp0FCDFL0LRkQ7YlGDhpZWr66u4Hi0Y3R0dBTWDgwMuCxqulpaWlym89kiUSSbCMkmQrKJkGwiEu3Go7s8u7q6XDY4OAhr9/b2XNbc3Axr0Q1G6ML36NA8OuTf3d0Na9H9qbncXapuXCSKZBMh2URINhFFuVwe7SRFzZWZ2fn5ucsaGxth7evrq8vQ7tLW1lY4HjVoUdOFlmFzuR0qKXQYX5iZZFMh2URINhGSTUTJf9QT6tyjDhl1w+j3K4WPZEoKdePCzCSbCskmQrKJKJnjP1HTFOUidzSziZBsIiSbCMkmQrKJkGwiJJsIySZCsomQbCKyvs8W/xea2URINhGSTYRkEyHZREg2EX8AUz9Tz55rWDYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEg0lEQVR4nO2dTSt8YRjGn/FWFmLhZacsyIoNC4odNrJRahRfwEJKJJ9ASuxEUoTEys6KBRkiGyyVklBeUkJ5+wD39cx/5s/MOea6fsvLfTj8eup2n+c8E/n6+nKCg6ygb0CkD8kmQrKJkGwiJJsIySYiJ94XX15eqP4vQ/+GZmXh9ZCdnW2yz89PWPvx8ZHwPUQikYRrEfn5+d5voJVNhGQTIdlESDYRcRu0TAA1Xb4mCDVdT09PsHZpaclkDQ0NsLampibeLaYNrWwiJJsIySZCsomQbCIyqhtPdNzpG4Hu7e2ZbGJiAtZubGyYbH5+HtbW1taaLIgdQlrZREg2EZJNhGQTkVENGhqDvr+/mywWi8Hr+/v7TXZ9fQ1rh4aGTNbS0vKvWwwUrWwiJJsIySZCsomQbCL+ZDfu23yAdnFOTU2ZzDcCbWxsNNnMzAysRSPQnBz850S7Tn+6i/R/0MomQrKJkGwiJJuI0DRovue76Nnzzc0NrJ2enk4oi0aj8PrR0VGTlZSUwFrUdPle/wmiGUNoZRMh2URINhGSTYRkExGJt8sxVS/jJ/P+FWJwcBDmm5ubJquvrzfZ5OQkvL6wsNBkvg4bEYauWy/jC+ecZFMh2URINhGBjEuTaWRWV1dNtrKyAmubmppMNj4+brKioiJ4fTKnGqExru/3Qg1pEKNVrWwiJJsIySZCsomQbCJC043f39/D2oWFBZO9vb3B2s7OTpOVlpaazNd1J9Nhv76+muz29hbWojFsQUEBrP3pKDkeWtlESDYRkk2EZBMRmgbt7u4O1p6fn5usrKwM1qJXctDP8j3Dv7q6Mtnh4SGsXVxcNNnl5SWs7evrM1lPTw+sTSVa2URINhGSTYRkExFIg4YapOPjY1iLDndvbW2FtVVVVSZ7eHgwGXrG7RxuBisrK2Ht4+Ojyc7OzmDtycmJyfQ8W6QUySZCsomQbCIkm4hAunHUie7v78Na9Oz69PQU1u7s7JhsfX3dZBcXF/D6sbExk6ERrHPOzc7Omuzo6AjWVldXm8x3shI6a1XPs0XSSDYRkk2EZBMRSIOGPvOyra0N1qINh+i5s3POdXd3m6y3t9dky8vL8HrUNK2trcFadA9oc6NzzlVUVJjM90xd41LxK0g2EZJNhGQTIdlEhGbzQl1dHaxFpx0dHBzAWtTJotGsb9yKuvS5uTlYW1xcbLKRkRFY29zcnNB9pRqtbCIkmwjJJkKyiQjkOEt4I54x4e7ursmGh4dhLdodit6j9v3OaFza1dUFawcGBkxWXl4Oa3Nzc2GeCnScpXDOSTYVkk2EZBMh2USE/nB5lD8/P8Pa7e1tk21tbZnMdzJTR0eHydrb22FtXl6eyXwj0HR+Fqe6ceGck2wqJJsIySYiNOPS39htmehxlL7vmczna4YVNWjCOSfZVEg2EZJNhGQTEcjuUsRvjA//WuecbrSyiZBsIiSbCMkmQrKJkGwiJJsIySZCsomQbCIkmwjJJkKyiZBsIiSbiLi7S0VmoZVNhGQTIdlESDYRkk2EZBPxDUNbRXu5oceTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAE20lEQVR4nO2dzSutXRjGb9+bCSUGQlFKiSQjJZkZkDI1UBQlQhkpExMfdUqJIWXoI0qJgTIwMiCmBvIxYMBAyc7n+wfc1xLxvHufc12/4eVe++z8zqrbetZaT8rHx4cJDlIT/QXE/4dkEyHZREg2EZJNhGQTkf7ZD+PxuP4u+8uIxWIpoZ9pZhMh2URINhGSTcSnDdq/QGqq//8c1fOAZH/OoJlNhGQTIdlESDYRkk3EX9mNp6TgFcH393eX3d/fuywjIwOOR3mow05P97+60Oei75UINLOJkGwiJJsIySYi6Rs0tNz59PQEa+fm5lw2Pz/vstLSUji+pKTEZS8vL7C2sLDQZX19fbC2urraZYlYWtXMJkKyiZBsIiSbCMkmIuWzrjAZdpdeX1+77M+fP7B2cXHRZVlZWS4rKCiA4xsaGlwWWprd3d11WV5eHqzd3t52WXFxMaz9aZeu3aXCzCSbCskmQrKJSMhyKWp6Dg8PYe3g4KDLTk9PYW1TU5PLhoaGXNbc3AzHZ2ZmuizUoC0tLblseHgY1u7s7List7cX1r69vcH8N9DMJkKyiZBsIiSbCMkmIiHdOFoSXFlZgbUnJycu6+rqgrVjY2MuKysrc1lotyf6XmgXqZlZRUWFy9DSrJnZ1dWVy0JdfpRoZhMh2URINhGSTUTS7C5Fy5pmZh0dHS6rq6uDtdnZ2S776fJjaDxqHOPxOKytrKx0mXaXikiRbCIkmwjJJkKyiUiabhydszLD57JCnWwUh95Dn3lzc+Oy0GH8mpoal6kbF5Ei2URINhGSTUTSNGihhiWKRib0LBkd/L+9vYW1q6urLqutrYW15eXlLlODJiJFsomQbCIkm4ikadB+g7S0NJehFbDX11c4HtVubW3BWrSJcHR0FNbm5OR86d+KGs1sIiSbCMkmQrKJkGwikqYbR0uVZnhpM9RNHx0duWx/f99lZ2dncDzaHXpwcABr0bGg0D2nyYJmNhGSTYRkEyHZRCTkOkvUjF1eXsLa9fV1l21ubsLai4sLl33nLT13d3cwR6CjRqHGcWFhwWXt7e2w9qfLqLrOUpiZZFMh2URINhGSTUSk3Xjos9GyZmdnJ6xF3WlLSwusRZfDNzY2uiy0IWFyctJlVVVVsHZiYsJlIyMjsBb9HtbW1mBtUVGRy77ToasbF2Ym2VRINhGSTcSvPc9GS6B7e3uwtru722WhqyCXl5ddhhoxM7xcicZPT0/D8bFYzGUzMzOwtr6+3mXoZiczs9nZWZeh891m+K1Av7UTVTObCMkmQrKJkGwiJJuIX+vG0S7Q0KH3x8dHl7W2tsJadDn88fExrJ2amnIZ2ugQetXT+Pi4y9Bb7c3wTtLQ0io664Uys2gP6WtmEyHZREg2EZJNxK89z0YH4UPHbNra2r76sbCRQQfhQ7U9PT0u6+/vh+Pz8/NdFlqqRM3n+fk5rN3Y2HDZwMAArEXvA/1O06bn2cLMJJsKySZCsomQbCIi3V0a6mQfHh5c9vz8/OXPDS3DojNcubm5LkN/OZhFd10Vel1U6Dv8FHXjwswkmwrJJkKyiUiaw/hRkYg7QhOJGjRhZpJNhWQTIdlESDYRCbm7lK1DThY0s4mQbCIkmwjJJuLT5VLxb6GZTYRkEyHZREg2EZJNhGQT8R/daGUQSM8D1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADn0lEQVR4nO2dvS60URRG9/iZoNGpJC5AopJQ6dQSJRcgolG7A4loFAqNRJQUEkoNjVKjEIVGI0KU/r8L2M+REfnGmXnWKp/ZL5NZTrKdd595G19fXwEe9Pz1G4D2gWwjkG0Eso1AthHINqLvuxdfX1/5v6zDaDabjdJrrGwjkG0Eso1AthHINgLZRiDbCGQbgWwjkG0Eso1AthHINgLZRiDbiG/vZ9dKb29vy7kalf74+JDXf35+/u6NVQ4r2whkG4FsI5BtBLKNqL4b7+nJf4+Hh4eydn19PWVjY2MpW1tbk9dPTEy09PsjdOde+yFJVrYRyDYC2UYg24jqG7RGI59meXt7a7l2YGAgZfPz8/L6mZmZlK2ursra8fHxlDWbTVn7/v4u83bDyjYC2UYg2whkG4FsIxrfbfHVcBhfddil4YOXl5eUDQ8Pp+zm5kZev729nbKDgwNZOzU1lbKVlRVZOz09LfP/AYfxISKQbQWyjUC2EdU3aArVtJVydd+5NJ2qPovHx0dZOzc3l7Lr62tZe3d396v38BNo0CAikG0Fso1AthHINqL64QVFqWNttZMtbbf29eWP4+npSdZeXl6mTE23ln7uX5wrY2UbgWwjkG0Eso3oyO3S31Laqnx4eEiZmjiNiJidnU3ZxsaGrG1ng8Z2KUQEsq1AthHINqLrGzR1j7t0HGdpaSllV1dXsvb8/DxlqhGLaO9uGQ0aRASyrUC2Ecg2AtlGdOT97J+gOuTT01NZu7e3l7KLiwtZ29/fn7LSffJaYGUbgWwjkG0Eso3oqgZN3ae+v79P2eLiorx+c3MzZZOTk7K29mZMwco2AtlGINsIZBuBbCM6cnihdBhffafpwsJCyp6fn+X1R0dHKRscHJS1tT4WiuEFiAhkW4FsI5BtREdul5aO7+zs7KTs5OQkZbe3t/L6oaGhlHXitmgJVrYRyDYC2UYg2whkG1H9dqnqvNWh+YiI0dHRlO3u7qZMbaFGlB8h1UmwXQoRgWwrkG0Eso2ovkFTDytfXl6WterL3Y+Pj1Omns8ZUe896p9AgwYRgWwrkG0Eso1AthHVDC+Uvlbq7OwsZfv7+7JWPWNTTYd200DCT2BlG4FsI5BtBLKNqKZBK23bqq3Nra0tWTsyMpIy12ZMwco2AtlGINsIZBuBbCOqH15Q06VqoCGiO6ZDfwvDCxARyLYC2UYg24hvGzToLljZRiDbCGQbgWwjkG0Eso34B5tc+Zvg+H8QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame(history.history)[10:20])\n",
    "\n",
    "predictions = np.argmax(model.predict(test_x), axis = 1)\n",
    "print_data(test_x, predictions, np.argmax(test_y, axis = 1), n, 5, (2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
