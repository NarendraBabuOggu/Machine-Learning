{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toyota Corolla Used Car Price Prediction Using Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from Excel Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToyotaCorolla = pd.read_excel(\"ToyotaCorolla.xlsx\", sheet_name = [0, 1])\n",
    "\n",
    "desc = ToyotaCorolla[0]\n",
    "data = ToyotaCorolla[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking The Invalid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Invalid data : \n",
      " Id                   0\n",
      "Model                0\n",
      "Price                0\n",
      "Age_08_04            0\n",
      "Mfg_Month            0\n",
      "Mfg_Year             0\n",
      "KM                   0\n",
      "Fuel_Type            0\n",
      "HP                   0\n",
      "Met_Color            0\n",
      "Color                0\n",
      "Automatic            0\n",
      "CC                   0\n",
      "Doors                0\n",
      "Cylinders            0\n",
      "Gears                0\n",
      "Quarterly_Tax        0\n",
      "Weight               0\n",
      "Mfr_Guarantee        0\n",
      "BOVAG_Guarantee      0\n",
      "Guarantee_Period     0\n",
      "ABS                  0\n",
      "Airbag_1             0\n",
      "Airbag_2             0\n",
      "Airco                0\n",
      "Automatic_airco      0\n",
      "Boardcomputer        0\n",
      "CD_Player            0\n",
      "Central_Lock         0\n",
      "Powered_Windows      0\n",
      "Power_Steering       0\n",
      "Radio                0\n",
      "Mistlamps            0\n",
      "Sport_Model          0\n",
      "Backseat_Divider     0\n",
      "Metallic_Rim         0\n",
      "Radio_cassette       0\n",
      "Parking_Assistant    0\n",
      "Tow_Bar              0\n",
      "dtype: int64\n",
      "Count of Invalid data : \n",
      " Variable       2\n",
      "Description    3\n",
      "dtype: int64\n",
      "Dropping NAN data from Description\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of Invalid data : \\n\", data.isna().sum())\n",
    "print(\"Count of Invalid data : \\n\", desc.isna().sum())\n",
    "print(\"Dropping NAN data from Description\")\n",
    "desc = desc.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Duplicate Columns and getting Metrics (We are already has the columns with age so no need for Mfg_Month, Mfg_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    count          mean           std     min      25%  \\\n",
      "Price              1436.0  10730.824513   3626.964585  4350.0   8450.0   \n",
      "Age_08_04          1436.0     55.947075     18.599988     1.0     44.0   \n",
      "KM                 1436.0  68533.259749  37506.448872     1.0  43000.0   \n",
      "HP                 1436.0    101.502089     14.981080    69.0     90.0   \n",
      "Met_Color          1436.0      0.674791      0.468616     0.0      0.0   \n",
      "Automatic          1436.0      0.055710      0.229441     0.0      0.0   \n",
      "CC                 1436.0   1576.855850    424.386770  1300.0   1400.0   \n",
      "Doors              1436.0      4.033426      0.952677     2.0      3.0   \n",
      "Cylinders          1436.0      4.000000      0.000000     4.0      4.0   \n",
      "Gears              1436.0      5.026462      0.188510     3.0      5.0   \n",
      "Quarterly_Tax      1436.0     87.122563     41.128611    19.0     69.0   \n",
      "Weight             1436.0   1072.459610     52.641120  1000.0   1040.0   \n",
      "Mfr_Guarantee      1436.0      0.409471      0.491907     0.0      0.0   \n",
      "BOVAG_Guarantee    1436.0      0.895543      0.305959     0.0      1.0   \n",
      "Guarantee_Period   1436.0      3.815460      3.011025     3.0      3.0   \n",
      "ABS                1436.0      0.813370      0.389750     0.0      1.0   \n",
      "Airbag_1           1436.0      0.970752      0.168559     0.0      1.0   \n",
      "Airbag_2           1436.0      0.722841      0.447751     0.0      0.0   \n",
      "Airco              1436.0      0.508357      0.500104     0.0      0.0   \n",
      "Automatic_airco    1436.0      0.056407      0.230786     0.0      0.0   \n",
      "Boardcomputer      1436.0      0.294568      0.456007     0.0      0.0   \n",
      "CD_Player          1436.0      0.218663      0.413483     0.0      0.0   \n",
      "Central_Lock       1436.0      0.580084      0.493717     0.0      0.0   \n",
      "Powered_Windows    1436.0      0.561978      0.496317     0.0      0.0   \n",
      "Power_Steering     1436.0      0.977716      0.147657     0.0      1.0   \n",
      "Radio              1436.0      0.146240      0.353469     0.0      0.0   \n",
      "Mistlamps          1436.0      0.256964      0.437111     0.0      0.0   \n",
      "Sport_Model        1436.0      0.300139      0.458478     0.0      0.0   \n",
      "Backseat_Divider   1436.0      0.770195      0.420854     0.0      1.0   \n",
      "Metallic_Rim       1436.0      0.204735      0.403649     0.0      0.0   \n",
      "Radio_cassette     1436.0      0.145543      0.352770     0.0      0.0   \n",
      "Parking_Assistant  1436.0      0.002786      0.052723     0.0      0.0   \n",
      "Tow_Bar            1436.0      0.277855      0.448098     0.0      0.0   \n",
      "\n",
      "                       50%       75%       max  \n",
      "Price               9900.0  11950.00   32500.0  \n",
      "Age_08_04             61.0     70.00      80.0  \n",
      "KM                 63389.5  87020.75  243000.0  \n",
      "HP                   110.0    110.00     192.0  \n",
      "Met_Color              1.0      1.00       1.0  \n",
      "Automatic              0.0      0.00       1.0  \n",
      "CC                  1600.0   1600.00   16000.0  \n",
      "Doors                  4.0      5.00       5.0  \n",
      "Cylinders              4.0      4.00       4.0  \n",
      "Gears                  5.0      5.00       6.0  \n",
      "Quarterly_Tax         85.0     85.00     283.0  \n",
      "Weight              1070.0   1085.00    1615.0  \n",
      "Mfr_Guarantee          0.0      1.00       1.0  \n",
      "BOVAG_Guarantee        1.0      1.00       1.0  \n",
      "Guarantee_Period       3.0      3.00      36.0  \n",
      "ABS                    1.0      1.00       1.0  \n",
      "Airbag_1               1.0      1.00       1.0  \n",
      "Airbag_2               1.0      1.00       1.0  \n",
      "Airco                  1.0      1.00       1.0  \n",
      "Automatic_airco        0.0      0.00       1.0  \n",
      "Boardcomputer          0.0      1.00       1.0  \n",
      "CD_Player              0.0      0.00       1.0  \n",
      "Central_Lock           1.0      1.00       1.0  \n",
      "Powered_Windows        1.0      1.00       1.0  \n",
      "Power_Steering         1.0      1.00       1.0  \n",
      "Radio                  0.0      0.00       1.0  \n",
      "Mistlamps              0.0      1.00       1.0  \n",
      "Sport_Model            0.0      1.00       1.0  \n",
      "Backseat_Divider       1.0      1.00       1.0  \n",
      "Metallic_Rim           0.0      0.00       1.0  \n",
      "Radio_cassette         0.0      0.00       1.0  \n",
      "Parking_Assistant      0.0      0.00       1.0  \n",
      "Tow_Bar                0.0      1.00       1.0  \n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns = ['Id', 'Mfg_Month', 'Mfg_Year'])\n",
    "metrics = data.describe().T\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiating between Sparse columns and Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model', 'Fuel_Type', 'Color'], dtype='object')\n",
      "Index(['Price', 'Age_08_04', 'KM', 'HP', 'CC', 'Doors', 'Gears',\n",
      "       'Quarterly_Tax', 'Weight', 'Guarantee_Period'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Guarantee_Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1170</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Age_08_04     KM  HP    CC  Doors  Gears  Quarterly_Tax  Weight  \\\n",
       "0  13500         23  46986  90  2000      3      5            210    1165   \n",
       "1  13750         23  72937  90  2000      3      5            210    1165   \n",
       "2  13950         24  41711  90  2000      3      5            210    1165   \n",
       "3  14950         26  48000  90  2000      3      5            210    1165   \n",
       "4  13750         30  38500  90  2000      3      5            210    1170   \n",
       "\n",
       "   Guarantee_Period  \n",
       "0                 3  \n",
       "1                 3  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types = data.dtypes\n",
    "categ_columns = data_types[data_types=='object']\n",
    "print(categ_columns.index)\n",
    "new_categ_data = pd.get_dummies(data, columns = categ_columns.index)\n",
    "sparse_columns = new_categ_data.columns[new_categ_data.nunique()>2]\n",
    "print(sparse_columns)\n",
    "new_categ_data[sparse_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the sparse data to a particular range using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91998\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gears</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_Beige</th>\n",
       "      <th>Color_Black</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Grey</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Silver</th>\n",
       "      <th>Color_Violet</th>\n",
       "      <th>Color_White</th>\n",
       "      <th>Color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.250444</td>\n",
       "      <td>2.784810</td>\n",
       "      <td>1.933547</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.339254</td>\n",
       "      <td>2.784810</td>\n",
       "      <td>3.001494</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.410302</td>\n",
       "      <td>2.911392</td>\n",
       "      <td>1.716468</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.765542</td>\n",
       "      <td>3.164557</td>\n",
       "      <td>1.975276</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.339254</td>\n",
       "      <td>3.670886</td>\n",
       "      <td>1.584328</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Age_08_04        KM        HP  Met_Color  Automatic       CC  \\\n",
       "0  3.250444   2.784810  1.933547  1.707317          1          0  0.47619   \n",
       "1  3.339254   2.784810  3.001494  1.707317          1          0  0.47619   \n",
       "2  3.410302   2.911392  1.716468  1.707317          1          0  0.47619   \n",
       "3  3.765542   3.164557  1.975276  1.707317          0          0  0.47619   \n",
       "4  3.339254   3.670886  1.584328  1.707317          0          0  0.47619   \n",
       "\n",
       "      Doors  Cylinders     Gears  ...  Color_Beige  Color_Black  Color_Blue  \\\n",
       "0  3.333333          4  6.666667  ...            0            0           1   \n",
       "1  3.333333          4  6.666667  ...            0            0           0   \n",
       "2  3.333333          4  6.666667  ...            0            0           1   \n",
       "3  3.333333          4  6.666667  ...            0            1           0   \n",
       "4  3.333333          4  6.666667  ...            0            1           0   \n",
       "\n",
       "   Color_Green  Color_Grey  Color_Red  Color_Silver  Color_Violet  \\\n",
       "0            0           0          0             0             0   \n",
       "1            0           0          0             1             0   \n",
       "2            0           0          0             0             0   \n",
       "3            0           0          0             0             0   \n",
       "4            0           0          0             0             0   \n",
       "\n",
       "   Color_White  Color_Yellow  \n",
       "0            0             0  \n",
       "1            0             0  \n",
       "2            0             0  \n",
       "3            0             0  \n",
       "4            0             0  \n",
       "\n",
       "[5 rows x 418 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scale = preprocessing.MinMaxScaler(feature_range = (0,10)).fit(new_categ_data[sparse_columns])\n",
    "new_categ_data[sparse_columns] = scale.transform(new_categ_data[sparse_columns])\n",
    "new_categ_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Test, Train and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Training Samples :  718\n",
      "No of Testing Samples :  574\n",
      "No of Validation Samples :  862\n"
     ]
    }
   ],
   "source": [
    "data_x = np.array(new_categ_data.drop(columns = ['Price']))\n",
    "data_y = np.array(new_categ_data[\"Price\"])\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.5, shuffle = True)\n",
    "test_x, val_x, test_y, val_y = train_test_split(data_x, data_y, test_size=0.6, shuffle = True)\n",
    "weights = np.random.randn(train_x.shape[1],1)\n",
    "m = train_x.shape[0]\n",
    "bias = np.random.randn()\n",
    "print(\"No of Training Samples : \",m)\n",
    "print(\"No of Testing Samples : \",test_x.shape[0])\n",
    "print(\"No of Validation Samples : \",val_x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Training for Prection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at epoch  0  :  18.380459833910255 (417, 1)\n",
      "Test Loss : at epoch  0  :  15.922641125977263\n",
      "Train Loss at epoch  1000  :  2.4079026912486166 (417, 1)\n",
      "Test Loss : at epoch  1000  :  2.45487463367133\n",
      "Train Loss at epoch  2000  :  1.8085637556048653 (417, 1)\n",
      "Test Loss : at epoch  2000  :  1.8851564727111285\n",
      "Train Loss at epoch  3000  :  1.5238546531334738 (417, 1)\n",
      "Test Loss : at epoch  3000  :  1.6019486559326992\n",
      "Train Loss at epoch  4000  :  1.3467564337004208 (417, 1)\n",
      "Test Loss : at epoch  4000  :  1.4213322973173907\n",
      "Train Loss at epoch  5000  :  1.2244660579222895 (417, 1)\n",
      "Test Loss : at epoch  5000  :  1.2962511240679937\n",
      "Train Loss at epoch  6000  :  1.133487717502314 (417, 1)\n",
      "Test Loss : at epoch  6000  :  1.2036805187272108\n",
      "Train Loss at epoch  7000  :  1.0619423011679217 (417, 1)\n",
      "Test Loss : at epoch  7000  :  1.131440857239016\n",
      "Train Loss at epoch  8000  :  1.0033696089620097 (417, 1)\n",
      "Test Loss : at epoch  8000  :  1.072782064110219\n",
      "Train Loss at epoch  9000  :  0.9540203447136761 (417, 1)\n",
      "Test Loss : at epoch  9000  :  1.0237578540958077\n",
      "Train Loss at epoch  10000  :  0.9115761810898486 (417, 1)\n",
      "Test Loss : at epoch  10000  :  0.9819240618727342\n",
      "Train Loss at epoch  11000  :  0.8745135842896399 (417, 1)\n",
      "Test Loss : at epoch  11000  :  0.945676559468502\n",
      "Train Loss at epoch  12000  :  0.8417739080307841 (417, 1)\n",
      "Test Loss : at epoch  12000  :  0.9139036059602927\n",
      "Train Loss at epoch  13000  :  0.8125852320918845 (417, 1)\n",
      "Test Loss : at epoch  13000  :  0.8857967852872924\n",
      "Train Loss at epoch  14000  :  0.7863620767216352 (417, 1)\n",
      "Test Loss : at epoch  14000  :  0.8607442534165223\n",
      "Train Loss at epoch  15000  :  0.7626464376879617 (417, 1)\n",
      "Test Loss : at epoch  15000  :  0.8382679910856026\n",
      "Train Loss at epoch  16000  :  0.7410714950879784 (417, 1)\n",
      "Test Loss : at epoch  16000  :  0.8179853129557704\n",
      "Train Loss at epoch  17000  :  0.7213382103238273 (417, 1)\n",
      "Test Loss : at epoch  17000  :  0.7995841823560512\n",
      "Train Loss at epoch  18000  :  0.7031995301088472 (417, 1)\n",
      "Test Loss : at epoch  18000  :  0.7828066574706695\n",
      "Train Loss at epoch  19000  :  0.6864492640056322 (417, 1)\n",
      "Test Loss : at epoch  19000  :  0.7674373070716104\n",
      "Train Loss at epoch  20000  :  0.6709139553687743 (417, 1)\n",
      "Test Loss : at epoch  20000  :  0.7532947851019457\n",
      "Train Loss at epoch  21000  :  0.656446751087111 (417, 1)\n",
      "Test Loss : at epoch  21000  :  0.7402254961886406\n",
      "Train Loss at epoch  22000  :  0.6429226600083585 (417, 1)\n",
      "Test Loss : at epoch  22000  :  0.7280987016080479\n",
      "Train Loss at epoch  23000  :  0.630234811467395 (417, 1)\n",
      "Test Loss : at epoch  23000  :  0.7168026553881651\n",
      "Train Loss at epoch  24000  :  0.6182914567907875 (417, 1)\n",
      "Test Loss : at epoch  24000  :  0.7062415019806427\n",
      "Train Loss at epoch  25000  :  0.6070135371797021 (417, 1)\n",
      "Test Loss : at epoch  25000  :  0.6963327530123996\n",
      "Train Loss at epoch  26000  :  0.5963326924201697 (417, 1)\n",
      "Test Loss : at epoch  26000  :  0.687005214565334\n",
      "Train Loss at epoch  27000  :  0.5861896183903696 (417, 1)\n",
      "Test Loss : at epoch  27000  :  0.6781972713969681\n",
      "Train Loss at epoch  28000  :  0.5765327041303234 (417, 1)\n",
      "Test Loss : at epoch  28000  :  0.6698554579891711\n",
      "Train Loss at epoch  29000  :  0.5673168952635067 (417, 1)\n",
      "Test Loss : at epoch  29000  :  0.6619332626276471\n",
      "Train Loss at epoch  30000  :  0.5585027421659976 (417, 1)\n",
      "Test Loss : at epoch  30000  :  0.6543901224286572\n",
      "Train Loss at epoch  31000  :  0.5500555999058845 (417, 1)\n",
      "Test Loss : at epoch  31000  :  0.6471905758860166\n",
      "Train Loss at epoch  32000  :  0.5419449535293053 (417, 1)\n",
      "Test Loss : at epoch  32000  :  0.640303546068174\n",
      "Train Loss at epoch  33000  :  0.5341438473373362 (417, 1)\n",
      "Test Loss : at epoch  33000  :  0.6337017326631751\n",
      "Train Loss at epoch  34000  :  0.5266284007732549 (417, 1)\n",
      "Test Loss : at epoch  34000  :  0.6273610950507215\n",
      "Train Loss at epoch  35000  :  0.519377396693938 (417, 1)\n",
      "Test Loss : at epoch  35000  :  0.6212604117487075\n",
      "Train Loss at epoch  36000  :  0.5123719303249245 (417, 1)\n",
      "Test Loss : at epoch  36000  :  0.6153809041281999\n",
      "Train Loss at epoch  37000  :  0.505595109236269 (417, 1)\n",
      "Test Loss : at epoch  37000  :  0.6097059143541168\n",
      "Train Loss at epoch  38000  :  0.4990317963300977 (417, 1)\n",
      "Test Loss : at epoch  38000  :  0.6042206291911981\n",
      "Train Loss at epoch  39000  :  0.4926683891799198 (417, 1)\n",
      "Test Loss : at epoch  39000  :  0.5989118426937323\n",
      "Train Loss at epoch  40000  :  0.4864926301671487 (417, 1)\n",
      "Test Loss : at epoch  40000  :  0.5937677519325031\n",
      "Train Loss at epoch  41000  :  0.48049344276941724 (417, 1)\n",
      "Test Loss : at epoch  41000  :  0.5887777808501519\n",
      "Train Loss at epoch  42000  :  0.47466079010553147 (417, 1)\n",
      "Test Loss : at epoch  42000  :  0.5839324281134317\n",
      "Train Loss at epoch  43000  :  0.4689855524629469 (417, 1)\n",
      "Test Loss : at epoch  43000  :  0.5792231354769893\n",
      "Train Loss at epoch  44000  :  0.4634594210491995 (417, 1)\n",
      "Test Loss : at epoch  44000  :  0.5746421737119284\n",
      "Train Loss at epoch  45000  :  0.4580748056378222 (417, 1)\n",
      "Test Loss : at epoch  45000  :  0.5701825436025219\n",
      "Train Loss at epoch  46000  :  0.4528247541373343 (417, 1)\n",
      "Test Loss : at epoch  46000  :  0.5658378898914814\n",
      "Train Loss at epoch  47000  :  0.44770288241137285 (417, 1)\n",
      "Test Loss : at epoch  47000  :  0.5616024263707516\n",
      "Train Loss at epoch  48000  :  0.4427033129290992 (417, 1)\n",
      "Test Loss : at epoch  48000  :  0.5574708705811712\n",
      "Train Loss at epoch  49000  :  0.4378206210359708 (417, 1)\n",
      "Test Loss : at epoch  49000  :  0.5534383868089522\n",
      "Train Loss at epoch  50000  :  0.43304978781258363 (417, 1)\n",
      "Test Loss : at epoch  50000  :  0.5495005362567216\n",
      "Train Loss at epoch  51000  :  0.42838615863915946 (417, 1)\n",
      "Test Loss : at epoch  51000  :  0.5456532334275566\n",
      "Train Loss at epoch  52000  :  0.423825406709977 (417, 1)\n",
      "Test Loss : at epoch  52000  :  0.5418927078967687\n",
      "Train Loss at epoch  53000  :  0.41936350084937807 (417, 1)\n",
      "Test Loss : at epoch  53000  :  0.5382154707620433\n",
      "Train Loss at epoch  54000  :  0.41499667707210663 (417, 1)\n",
      "Test Loss : at epoch  54000  :  0.5346182851611969\n",
      "Train Loss at epoch  55000  :  0.4107214134082181 (417, 1)\n",
      "Test Loss : at epoch  55000  :  0.5310981403309609\n",
      "Train Loss at epoch  56000  :  0.4065344075788131 (417, 1)\n",
      "Test Loss : at epoch  56000  :  0.5276522287521045\n",
      "Train Loss at epoch  57000  :  0.40243255716519133 (417, 1)\n",
      "Test Loss : at epoch  57000  :  0.524277925987748\n",
      "Train Loss at epoch  58000  :  0.3984129419622025 (417, 1)\n",
      "Test Loss : at epoch  58000  :  0.5209727728744764\n",
      "Train Loss at epoch  59000  :  0.3944728082478219 (417, 1)\n",
      "Test Loss : at epoch  59000  :  0.5177344597711634\n",
      "Train Loss at epoch  60000  :  0.3906095547363863 (417, 1)\n",
      "Test Loss : at epoch  60000  :  0.5145608126093656\n",
      "Train Loss at epoch  61000  :  0.38682072001334006 (417, 1)\n",
      "Test Loss : at epoch  61000  :  0.5114497805226916\n",
      "Train Loss at epoch  62000  :  0.38310397127552526 (417, 1)\n",
      "Test Loss : at epoch  62000  :  0.50839942486149\n",
      "Train Loss at epoch  63000  :  0.37945709422362206 (417, 1)\n",
      "Test Loss : at epoch  63000  :  0.5054079094241672\n",
      "Train Loss at epoch  64000  :  0.3758779839728283 (417, 1)\n",
      "Test Loss : at epoch  64000  :  0.5024734917580616\n",
      "Train Loss at epoch  65000  :  0.3723646368647239 (417, 1)\n",
      "Test Loss : at epoch  65000  :  0.49959451540149785\n",
      "Train Loss at epoch  66000  :  0.3689151430778555 (417, 1)\n",
      "Test Loss : at epoch  66000  :  0.4967694029548611\n",
      "Train Loss at epoch  67000  :  0.3655276799472272 (417, 1)\n",
      "Test Loss : at epoch  67000  :  0.49399664988259895\n",
      "Train Loss at epoch  68000  :  0.36220050591387487 (417, 1)\n",
      "Test Loss : at epoch  68000  :  0.49127481896028913\n",
      "Train Loss at epoch  69000  :  0.35893195503525815 (417, 1)\n",
      "Test Loss : at epoch  69000  :  0.4886025352915398\n",
      "Train Loss at epoch  70000  :  0.3557204319955193 (417, 1)\n",
      "Test Loss : at epoch  70000  :  0.4859784818287569\n",
      "Train Loss at epoch  71000  :  0.3525644075619183 (417, 1)\n",
      "Test Loss : at epoch  71000  :  0.48340139533987436\n",
      "Train Loss at epoch  72000  :  0.34946241444008014 (417, 1)\n",
      "Test Loss : at epoch  72000  :  0.4808700627701911\n",
      "Train Loss at epoch  73000  :  0.34641304348623075 (417, 1)\n",
      "Test Loss : at epoch  73000  :  0.4783833179546076\n",
      "Train Loss at epoch  74000  :  0.34341494023943825 (417, 1)\n",
      "Test Loss : at epoch  74000  :  0.4759400386409252\n",
      "Train Loss at epoch  75000  :  0.34046680174112076 (417, 1)\n",
      "Test Loss : at epoch  75000  :  0.4735391437895786\n",
      "Train Loss at epoch  76000  :  0.3375673736128065 (417, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : at epoch  76000  :  0.4711795911192839\n",
      "Train Loss at epoch  77000  :  0.33471544736639924 (417, 1)\n",
      "Test Loss : at epoch  77000  :  0.4688603748716982\n",
      "Train Loss at epoch  78000  :  0.3319098579240781 (417, 1)\n",
      "Test Loss : at epoch  78000  :  0.4665805237713453\n",
      "Train Loss at epoch  79000  :  0.32914948132748667 (417, 1)\n",
      "Test Loss : at epoch  79000  :  0.4643390991598413\n",
      "Train Loss at epoch  80000  :  0.3264332326181024 (417, 1)\n",
      "Test Loss : at epoch  80000  :  0.46213519328589064\n",
      "Train Loss at epoch  81000  :  0.3237600638726331 (417, 1)\n",
      "Test Loss : at epoch  81000  :  0.45996792773466816\n",
      "Train Loss at epoch  82000  :  0.32112896237903354 (417, 1)\n",
      "Test Loss : at epoch  82000  :  0.45783645198208717\n",
      "Train Loss at epoch  83000  :  0.31853894894026163 (417, 1)\n",
      "Test Loss : at epoch  83000  :  0.4557399420611112\n",
      "Train Loss at epoch  84000  :  0.31598907629425377 (417, 1)\n",
      "Test Loss : at epoch  84000  :  0.45367759932872775\n",
      "Train Loss at epoch  85000  :  0.3134784276398004 (417, 1)\n",
      "Test Loss : at epoch  85000  :  0.45164864932349186\n",
      "Train Loss at epoch  86000  :  0.31100611525907085 (417, 1)\n",
      "Test Loss : at epoch  86000  :  0.44965234070467813\n",
      "Train Loss at epoch  87000  :  0.3085712792284778 (417, 1)\n",
      "Test Loss : at epoch  87000  :  0.4476879442650851\n",
      "Train Loss at epoch  88000  :  0.3061730862104152 (417, 1)\n",
      "Test Loss : at epoch  88000  :  0.4457547520104165\n",
      "Train Loss at epoch  89000  :  0.30381072831914874 (417, 1)\n",
      "Test Loss : at epoch  89000  :  0.44385207629894585\n",
      "Train Loss at epoch  90000  :  0.30148342205480244 (417, 1)\n",
      "Test Loss : at epoch  90000  :  0.44197924903585883\n",
      "Train Loss at epoch  91000  :  0.2991904072999798 (417, 1)\n",
      "Test Loss : at epoch  91000  :  0.4401356209172812\n",
      "Train Loss at epoch  92000  :  0.2969309463740814 (417, 1)\n",
      "Test Loss : at epoch  92000  :  0.43832056071953573\n",
      "Train Loss at epoch  93000  :  0.2947043231408543 (417, 1)\n",
      "Test Loss : at epoch  93000  :  0.43653345462964854\n",
      "Train Loss at epoch  94000  :  0.2925098421651338 (417, 1)\n",
      "Test Loss : at epoch  94000  :  0.4347737056135557\n",
      "Train Loss at epoch  95000  :  0.29034682791510613 (417, 1)\n",
      "Test Loss : at epoch  95000  :  0.4330407328188224\n",
      "Train Loss at epoch  96000  :  0.2882146240067653 (417, 1)\n",
      "Test Loss : at epoch  96000  :  0.4313339710090317\n",
      "Train Loss at epoch  97000  :  0.2861125924875366 (417, 1)\n",
      "Test Loss : at epoch  97000  :  0.4296528700272887\n",
      "Train Loss at epoch  98000  :  0.2840401131563103 (417, 1)\n",
      "Test Loss : at epoch  98000  :  0.42799689428654564\n",
      "Train Loss at epoch  99000  :  0.2819965829173706 (417, 1)\n",
      "Test Loss : at epoch  99000  :  0.42636552228469055\n",
      "Scores on Train, Test and Validation data : ;0.7357223151376389;0.7357223151376389;0.7357223151376389\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Custom Training \n",
    "y_pred = 0\n",
    "loss = 0\n",
    "grad = 0\n",
    "test_pred = 0\n",
    "test_loss = 0\n",
    "lr = 0.001\n",
    "for i in range(100000):\n",
    "    y_pred = (np.dot(train_x, weights) + bias).flatten()\n",
    "    #print(y_pred.shape, train_y.shape)\n",
    "    loss = np.sum(np.square(y_pred - train_y))/m\n",
    "    grad = 2 * np.dot(train_x.T, (y_pred-train_y).reshape(train_y.shape[0],1))/m\n",
    "    weights = weights - lr * grad\n",
    "    bias = bias - lr * np.sum(y_pred - train_y)\n",
    "    if (i%1000==0):\n",
    "        print(\"Train Loss at epoch \", i, \" : \",loss,weights.shape)\n",
    "        val_pred = (np.dot(val_x, weights) + bias).flatten()\n",
    "        val_loss = np.sum(np.square(val_pred - val_y))/val_y.shape[0]\n",
    "        print(\"Test Loss : at epoch \", i, \" : \",val_loss)\n",
    "\n",
    "#Predicting Score\n",
    "from sklearn.metrics import r2_score\n",
    "test_pred = (np.dot(test_x, weights) + bias).flatten()\n",
    "train_pred = (np.dot(train_x, weights) + bias).flatten()\n",
    "val_pred = (np.dot(val_x, weights) + bias).flatten()\n",
    "train_score = r2_score(test_y, test_pred)\n",
    "test_score = r2_score(test_y, test_pred)\n",
    "val_score = r2_score(test_y, test_pred)\n",
    "print(\"Scores on Train, Test and Validation data : \",train_score, test_score, val_score, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Support Vector Machine for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91998\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score using SVR Training :  0.8857827231578715\n",
      "Model Score using Custom Training :  0.7357223151376389\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "svr = SVR()\n",
    "model = svr.fit(train_x, train_y)\n",
    "print(\"Model Score using SVR Training : \", svr.score(test_x, test_y))\n",
    "print(\"Model Score using Custom Training : \", test_score)\n",
    "pred = svr.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting The Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value :  1.3854351687388988  Custom Predicted Value :  1.7965956526080822  SVR Predicted Value :  1.7763292487462583\n",
      "Actual Value :  1.6341030195381883  Custom Predicted Value :  1.6709528142521322  SVR Predicted Value :  1.7014145086542674\n",
      "Actual Value :  2.3445825932504443  Custom Predicted Value :  2.6501037791740445  SVR Predicted Value :  2.789859708335007\n",
      "Actual Value :  1.3854351687388988  Custom Predicted Value :  2.91772550222202  SVR Predicted Value :  1.5565596843833491\n",
      "Actual Value :  2.3445825932504443  Custom Predicted Value :  2.155639732834012  SVR Predicted Value :  2.1807684853865656\n",
      "Actual Value :  1.2788632326820604  Custom Predicted Value :  1.6428681769957727  SVR Predicted Value :  1.550384254741774\n",
      "Actual Value :  6.625222024866785  Custom Predicted Value :  3.7873467376833054  SVR Predicted Value :  5.362016885765017\n",
      "Actual Value :  1.3854351687388988  Custom Predicted Value :  3.193913120922674  SVR Predicted Value :  1.669238258903293\n",
      "Actual Value :  1.9715808170515097  Custom Predicted Value :  2.129746278113137  SVR Predicted Value :  1.8852873016043947\n",
      "Actual Value :  1.030195381882771  Custom Predicted Value :  0.9979560654548782  SVR Predicted Value :  0.9508370954299332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x233f6703278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y, z in zip(test_y[:10], test_pred[:10], pred[:10]):\n",
    "    print(\"Actual Value : \", x, \" Custom Predicted Value : \", y, \" SVR Predicted Value : \", z)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(test_y, test_y, c = \"g\")\n",
    "plt.scatter(test_y, pred, c = 'b')\n",
    "plt.scatter(test_y, test_pred, c = \"r\")\n",
    "plt.legend([ 'Actual Values', 'SVR Predicted', 'Custom Predicted'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
